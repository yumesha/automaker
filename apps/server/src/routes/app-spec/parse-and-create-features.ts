/**
 * Parse agent response and create feature files
 */

import path from 'path';
import * as secureFs from '../../lib/secure-fs.js';
import type { EventEmitter } from '../../lib/events.js';
import { createLogger } from '@automaker/utils';
import { getFeaturesDir } from '@automaker/platform';
import { extractJsonWithArray } from '../../lib/json-extractor.js';

const logger = createLogger('SpecRegeneration');

export async function parseAndCreateFeatures(
  projectPath: string,
  content: string,
  events: EventEmitter,
  targetBranch?: string
): Promise<void> {
  logger.info('========== parseAndCreateFeatures() started ==========');
  logger.info(`Content length: ${content.length} chars`);
  logger.info('targetBranch:', targetBranch);
  logger.info('========== CONTENT RECEIVED FOR PARSING ==========');
  logger.info(content);
  logger.info('========== END CONTENT ==========');

  try {
    // Extract JSON from response using shared utility
    logger.info('Extracting JSON from response using extractJsonWithArray...');

    interface FeaturesResponse {
      features: Array<{
        id: string;
        category?: string;
        title: string;
        description: string;
        priority?: number;
        complexity?: string;
        dependencies?: string[];
      }>;
    }

    const parsed = extractJsonWithArray<FeaturesResponse>(content, 'features', { logger });

    if (!parsed || !parsed.features) {
      logger.error('❌ No valid JSON with "features" array found in response');
      logger.error('Full content received:');
      logger.error(content);
      throw new Error('No valid JSON found in response');
    }

    logger.info(`Parsed ${parsed.features?.length || 0} features`);
    logger.info('Parsed features:', JSON.stringify(parsed.features, null, 2));

    const featuresDir = getFeaturesDir(projectPath);
    await secureFs.mkdir(featuresDir, { recursive: true });

    // Delete existing features for this branch before creating new ones
    if (targetBranch) {
      logger.info(`Deleting existing features for branch '${targetBranch}'...`);
      try {
        const existingFeatures = await secureFs.readdir(featuresDir);
        let deletedCount = 0;

        for (const featureId of existingFeatures) {
          const featureJsonPath = path.join(featuresDir, featureId, 'feature.json');
          try {
            const featureContent = (await secureFs.readFile(featureJsonPath, 'utf-8')) as string;
            const featureData = JSON.parse(featureContent);

            // Delete if it matches the target branch
            if (featureData.branchName === targetBranch) {
              logger.info(`Deleting feature ${featureId} from branch ${targetBranch}`);
              await secureFs.rm(path.join(featuresDir, featureId), { recursive: true });
              deletedCount++;
            }
          } catch (err) {
            // Skip if feature.json doesn't exist or can't be read
            logger.debug(`Skipping ${featureId}: ${err}`);
          }
        }

        logger.info(`✓ Deleted ${deletedCount} existing features for branch '${targetBranch}'`);
      } catch (err) {
        logger.warn('Failed to delete existing features:', err);
        // Continue anyway - not critical
      }
    }

    const createdFeatures: Array<{ id: string; title: string }> = [];

    for (const feature of parsed.features) {
      logger.debug('Creating feature:', feature.id);
      const featureDir = path.join(featuresDir, feature.id);
      await secureFs.mkdir(featureDir, { recursive: true });

      const featureData = {
        id: feature.id,
        category: feature.category || 'Uncategorized',
        title: feature.title,
        description: feature.description,
        status: 'backlog', // Features go to backlog - user must manually start them
        priority: feature.priority || 2,
        complexity: feature.complexity || 'moderate',
        dependencies: feature.dependencies || [],
        branchName: targetBranch || 'main',
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
      };

      await secureFs.writeFile(
        path.join(featureDir, 'feature.json'),
        JSON.stringify(featureData, null, 2)
      );

      createdFeatures.push({ id: feature.id, title: feature.title });
    }

    logger.info(`✓ Created ${createdFeatures.length} features successfully`);

    // Calculate worktree path for the target branch
    let worktreePath: string | undefined;
    if (targetBranch && targetBranch !== 'main' && targetBranch !== 'master') {
      worktreePath = path.join(projectPath, '.worktrees', targetBranch);
    }

    events.emit('spec-regeneration:event', {
      type: 'spec_regeneration_complete',
      message: `Spec regeneration complete! Created ${createdFeatures.length} features.`,
      projectPath: projectPath,
      targetBranch: targetBranch,
      worktreePath: worktreePath,
    });
  } catch (error) {
    logger.error('❌ parseAndCreateFeatures() failed:');
    logger.error('Error:', error);
    events.emit('spec-regeneration:event', {
      type: 'spec_regeneration_error',
      error: (error as Error).message,
      projectPath: projectPath,
    });
  }

  logger.debug('========== parseAndCreateFeatures() completed ==========');
}
